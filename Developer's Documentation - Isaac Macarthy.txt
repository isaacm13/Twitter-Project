External Documentation
Overview: This project is targeted towards marketers as the stakeholders to use Twitter user's data for purposes of enhancing, but not limited to their product or services in interacting with their target audience. By having the data collected from user's based on their account and the trending topics, by hashtags, it is pulled into a statistical analysis to sort through the different views of presenting the data.
The statistical analysis is based on the sentiment analysis of Twitter. Which calculates the sentiment score for the compound, positive, negative, and neutral score of tweets/hashtags analyze. 
This data is presented in data frames, .csv files, and charts for the marketers. 
This python project is located on Github at https://github.com/isaacm13/Twitter-Project 
This python project aims to pull data from the social media platform Twitter. Twitter is a social media platform that allows users to interact with others over a social network, as long as they have an account, and enable the interaction amongst other users through varying features, but primarily, tweets. Twitter users post tweets that can convey a status update of their choosing. These tweets vary amongst users with what data it contains, such as the text of the tweet, location, amount of favorites or retweets, and the user's account name. Thus, to sort and collect this information from a tweet is associated with Twitter API. 
To pull this data, the python module that was worked with was called Tweepy. Tweepy, in short, can work with Twitter's API by extracting the data from the user's account, if public or followed by the user running the code. To be able to use Tweepy, a developer's account must be created, as this is the legally approved method by Twitter for the user's to pull data from another on their platform.
For the initial start of running this code and further guidance, the user can refer to the README.md file. 

Once the user reads the README.md file, they can proceed with the other steps of the code.
1. Developer account is needed to run the code for working with Twitter's API. 
This will generate the specific keys for that user to work from pulling Twitter's API. These keys are the consumer key, consumer secret, access token, and the access token are required.
2. Refer to the requirement.txt of the packages to install prerequisites with pip 

The user can tell navigate to with folder of Part 1 Specific Twitter Analysis or Part 2 User Input Twitter Analysis to run the Twitter Sentiment Analysis of pulling user data from Twitter. 
(End) User interaction
Once the user navigates through the main.py to have an understanding of what is required and how to run the code, they can proceed to the first folder of Part 1 Specific Twitter Analysis or Part 2 User Input Twitter Analysis and get started with interaction of the code
The first file there is Trending Topic of Specific Set Users.ipyy, either the notebook file or python is applicable to run. 

The reason for having the two is the notebook having the cells ran already to see how the code should be outputted once running of the python code through their interpreter.
With this first file, the user will have a topic analysis of set user's accounter, chosen by the developer, me, to see that collected from those Twitter accounts.
The reason I chose these Twitter accounts; @socialmedia2day @GoogleAds @Instagram @Twitter @Facebook, because they are amongst the top popular interactive and social accounts on Twitter that adhere to my target stakeholders of marketers, to cypher through the data collected to be of use their company when coming up with a product or service to their consumer base.
As when they see what is trending from those accounts, they can implement what users are searching for/doing on Twitter to be able to reach out them.
For instance, seeing the top hashtags used amongst those accounts, they can incorporate those hashtags into their tweets (the marketers) so it can reach that audience, since they are using a trending hashtag that was pulled as data from those accounts 
As seen here from a piece of code that generates the positive hashtags pulled from tweet data, to see the trending hashtags of most recent tweets

And once the hashtags are pulled, the user, which is targeted towards marketers, can see it in the form of a sentiment analysis of a score table and bar graph which Twitter account generates the most interactiveness of Tweets on a score of being compound, positive, negative, or neutral. 

This shows of further code files, of what statistical portions are displayed to the user to see the data pull into an organized visual. 
Further if going on to the second folder of Part 2 User Input Twitter Analysis will allow the user the freedom to enter what ever user they know, and pull data from their account, rather than the first part of having set users. 
This gives the user the freedom to comb through other accounts for use their data
And, again displays different results of the Twitter sentiment analysis conducted throughout this project.


Lastly, other than the visuals of data displayed through tables, charts, graphs, and word clouds, there are also txt files and csv files that generated to comb through the data pulled and be seen in raw format of txt or through a spreadsheet by csv file. 


Known Issues
The known issues are with the second part folder of the code being Part 2 User Input Twitter Analysis and the file User Input Hashtag Live Stream. 
As this piece of code continuously runs after the user runs it, and it only for the purpose of being used to see live tweets. 
As since it is constantly running to see the live tweets, this generates the memory of storage to increase and can cause the code to be a bigger file than what is cable of being held within the repository. 
Future work
The future plans for this Twitter Sentiment Analysis project code, through the Tweepy module, is to generate clear view of data pulled with concise columns that if a user came across this without prior knowledge of Twitter, they should be able to get what data is pulled
For instance, that a favorite_count and retweet_count, which are columns in the tweetspreadsheet.csv in the part 2, are about the interactiveness of other users of a tweet posted.
As favorite_count is how many likes the tweet has, and retweet_count is how many times the tweet has been shared amongst in the Twitter platform to other users

So, overall is generate a csv file for each file ran, so that data is presented in a spreadsheet for a quick run through of the data pulled, rather than having to sort through each file ran and having to look at each visual of data, whether it be a table to graph.
The csv file would have all the data from a table or graph all in one clear view by it being a spreadsheet.
Isaac Macarthy
Developer's documentation
HCI 584X
